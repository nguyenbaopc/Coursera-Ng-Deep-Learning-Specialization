# Deep Learning Specialization

Course can be found in [Coursera](https://www.coursera.org/specializations/deep-learning)

Quiz and answers are collected in my blog [SSQ](https://ssq.github.io/2017/08/28/Coursera%20Ng%20Deep%20Learning%20Specialization%20Notebook/)

## 1. Neural Networks and Deep Learning

Course can be found in [Coursera](https://www.coursera.org/learn/neural-networks-deep-learning)

Slides and more details about this course can be found in my Github [SSQ](https://github.com/SSQ/Coursera-Ng-Neural-Networks-and-Deep-Learning)

- Week 1:
  - Understand the major trends driving the rise of deep learning.
  - Be able to explain how deep learning is applied to supervised learning.
  - Understand what are the major categories of models (such as CNNs and RNNs), and when they should be applied.
  - Be able to recognize the basics of when deep learning will (or will not) work well.
- Week 2:
  - Build a logistic regression model, structured as a shallow neural network
  - Implement the main steps of an ML algorithm, including making predictions, derivative computation, and gradient descent.
  - Implement computationally efficient, highly vectorized, versions of models.
  - Understand how to compute derivatives for logistic regression, using a backpropagation mindset.
  - Become familiar with Python and Numpy
  - Work with iPython Notebooks
  - Be able to implement vectorization across multiple training examples
  - [x] [Python Basics with Numpy (optional assignment)]()
  - [x] [Logistic Regression with a Neural Network mindset](https://github.com/SSQ/Coursera-Ng-Neural-Networks-and-Deep-Learning/tree/master/Pragramming%20Assignment%201)
- Week 3:
  - Understand hidden units and hidden layers
  - Be able to apply a variety of activation functions in a neural network.
  - Build your first forward and backward propagation with a hidden layer
  - Apply random initialization to your neural network
  - Become fluent with Deep Learning notations and Neural Network Representations
  - Build and train a neural network with one hidden layer.
  - [x] [Build a 2-class classification complete neural network with a hidden layer](https://github.com/SSQ/Coursera-Ng-Neural-Networks-and-Deep-Learning/tree/master/Week%203%20PA%201)
- Week 4:
  - See deep neural networks as successive blocks put one after each other
  - Build and train a deep L-layer Neural Network
  - Analyze matrix and vector dimensions to check neural network implementations.
  - Understand how to use a cache to pass information from forward propagation to back propagation.
  - Understand the role of hyperparameters in deep learning
  - [x] [Building Deep Neural Network: Step by Step](https://github.com/SSQ/Coursera-Ng-Neural-Networks-and-Deep-Learning/tree/master/Week%204%20PA%201)
  - [x] [Deep Neural Network for Image Classification: Application](https://github.com/SSQ/Coursera-Ng-Neural-Networks-and-Deep-Learning/tree/master/Week%204%20PA%202)

## 2. Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization

Course can be found in [Coursera](https://www.coursera.org/learn/deep-neural-network)

Slides and more details about this course can be found in my Github [SSQ](https://github.com/SSQ/Coursera-Ng-Improving-Deep-Neural-Networks-Hyperparameter-tuning-Regularization-and-Optimization)

- Week 1 Practical aspects of Deep Learning
  - Recall that different types of initializations lead to different results
  - Recognize the importance of initialization in complex neural networks.
  - Recognize the difference between train/dev/test sets
  - Diagnose the bias and variance issues in your model
  - Learn when and how to use regularization methods such as dropout or L2 regularization.
  - Understand experimental issues in deep learning such as Vanishing or Exploding gradients and learn how to deal with them
  - Use gradient checking to verify the correctness of your backpropagation implementation
  - [x] [Initialization](https://github.com/SSQ/Coursera-Ng-Improving-Deep-Neural-Networks-Hyperparameter-tuning-Regularization-and-Optimization/tree/master/Week%201%20PA%201)
  - [x] [Regularization](https://github.com/SSQ/Coursera-Ng-Improving-Deep-Neural-Networks-Hyperparameter-tuning-Regularization-and-Optimization/tree/master/Week%201%20PA%202)
  - [x] [Gradient Checking](https://github.com/SSQ/Coursera-Ng-Improving-Deep-Neural-Networks-Hyperparameter-tuning-Regularization-and-Optimization/tree/master/Week%201%20PA%203)
- Week 2 Optimization algorithms
  - Remember different optimization methods such as (Stochastic) Gradient Descent, Momentum, RMSProp and Adam
  - Use random minibatches to accelerate the convergence and improve the optimization
  - Know the benefits of learning rate decay and apply it to your optimization
  - [x] [Optimization](https://github.com/SSQ/Coursera-Ng-Improving-Deep-Neural-Networks-Hyperparameter-tuning-Regularization-and-Optimization/tree/master/Week%202%20PA%201)
- Week 3 Hyperparameter tuning, Batch Normalization and Programming Frameworks
  - Master the process of hyperparameter tuning
  - Master the process of batch Normalization
  - [x] [Tensorflow](https://github.com/SSQ/Coursera-Ng-Improving-Deep-Neural-Networks-Hyperparameter-tuning-Regularization-and-Optimization/tree/master/Week%203%20PA%201)

## 3. Structuring Machine Learning Projects

Course can be found in [Coursera](https://www.coursera.org/learn/machine-learning-projects)

Slides and more details about this course can be found in my Github [SSQ](https://github.com/SSQ/Coursera-Ng-Structuring-Machine-Learning-Projects)

- Week 1 ML Strategy (1)
  - Understand why Machine Learning strategy is important
  - Apply satisficing and optimizing metrics to set up your goal for ML projects
  - Choose a correct train/dev/test split of your dataset
  - Understand how to define human-level performance
  - Use human-level perform to define your key priorities in ML projects
  - Take the correct ML Strategic decision based on observations of performances and dataset
- Week 2 ML Strategy (2)
  - Understand what multi-task learning and transfer learning are
  - Recognize bias, variance and data-mismatch by looking at the performances of your algorithm on train/dev/test sets

## 4. Convolutional Neural Networks

Course can be found in [Coursera](https://www.coursera.org/learn/convolutional-neural-networks)

Slides and more details about this course can be found in my Github [SSQ](https://github.com/SSQ/Coursera-Ng-Convolutional-Neural-Networks)

- Week 1 Foundations of Convolutional Neural Networks
  - Understand the convolution operation
  - Understand the pooling operation
  - Remember the vocabulary used in convolutional neural network (padding, stride, filter, ...)
  - Build a convolutional neural network for image multi-class classification
  - [x] [Convolutional Model: step by step](https://github.com/SSQ/Coursera-Ng-Convolutional-Neural-Networks/tree/master/Week%201%20PA%201%20Convolution%20model%20-%20Step%20by%20Step%20-%20v2)
  - [x] [Convolutional Model: application](https://github.com/SSQ/Coursera-Ng-Convolutional-Neural-Networks/tree/master/Week%201%20PA%202%20Convolution%20model%20-%20Application%20-%20v1)

- Week 2 Deep convolutional models: case studies
  - Understand multiple foundational papers of convolutional neural networks
  - Analyze the dimensionality reduction of a volume in a very deep network
  - Understand and Implement a Residual network
  - Build a deep neural network using Keras
  - Implement a skip-connection in your network
  - Clone a repository from github and use transfer learning
  - [x] [Keras - Tutorial - Happy House v2](https://github.com/SSQ/Coursera-Ng-Convolutional-Neural-Networks/tree/master/Week%202%20PA%201%20Keras%20-%20Tutorial%20-%20Happy%20House%20v2)
  - [x] [Residual Networks - v2](https://github.com/SSQ/Coursera-Ng-Convolutional-Neural-Networks/tree/master/Week%202%20PA%202%20Residual%20Networks%20-%20v2)
  
- Week 3 Object detection
  - Understand the challenges of Object Localization, Object Detection and Landmark Finding
  - Understand and implement non-max suppression
  - Understand and implement intersection over union
  - Understand how we label a dataset for an object detection application
  - Remember the vocabulary of object detection (landmark, anchor, bounding box, grid, ...)
  - [x] [Car detection with YOLOv2](https://github.com/SSQ/Coursera-Ng-Convolutional-Neural-Networks/tree/master/Week%203%20PA%201%20Car%20detection%20with%20YOLOv2)
  
- Week 4 Special applications: Face recognition & Neural style transfer
  - Understand One Shot Learning, Siamese Network, Triplet Loss
  - Understand Content Cost Function, Style Cost Function, 1D and 3D Generalizations
  - [x] [Deep Learning & Art: Neural Style Transfer](https://github.com/SSQ/Coursera-Ng-Convolutional-Neural-Networks/tree/master/Week%204%20PA%201%20Art%20generation%20with%20Neural%20Style%20Transfer)
  - [x] [Face Recognition for the Happy House](https://github.com/SSQ/Coursera-Ng-Convolutional-Neural-Networks/tree/master/Week%204%20PA%202%20Face%20Recognition%20for%20the%20Happy%20House)
  
  
  ## 5. Sequence Models
Course can be found in Coursera

Quiz and answers are collected for quick search in my blog SSQ

[Github](https://github.com/SSQ/Coursera-Ng-Sequence-Models)
Week 1 Recurrent Neural Networks

Learn about recurrent neural networks, including LSTMs, GRUs and Bidirectional RNNs.
 Building a recurrent neural network - step by step
 Dinosaur Island - Character-Level Language Modeling
 Jazz improvisation with LSTM
Week 2 Natural Language Processing & Word Embeddings

Word Representation, Word embeddings, Embedding matrix
Word2Vec & GloVe
Sentiment Classification
Debiasing word embeddings
 Operations on word vectors - Debiasing
 Emojify
Week 3 Sequence models & Attention mechanism
